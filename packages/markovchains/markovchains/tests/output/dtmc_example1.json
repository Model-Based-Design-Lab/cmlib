{
    "states": "[A_s0, B1, C]",
    "rewardVector": "[1.0000, 2.0000, 0.0000]",
    "executeSteps_0": "[[1.0000, 0.0000, 0.0000]]",
    "executeSteps_15": "[[1.0000, 0.0000, 0.0000], [0.5000, 0.5000, 0.0000], [0.2500, 0.5000, 0.2500], [0.1250, 0.5000, 0.3750], [0.0625, 0.5000, 0.4375], [0.0312, 0.5000, 0.4688], [0.0156, 0.5000, 0.4844], [0.0078, 0.5000, 0.4922], [0.0039, 0.5000, 0.4961], [0.0020, 0.5000, 0.4980], [0.0010, 0.5000, 0.4990], [0.0005, 0.5000, 0.4995], [0.0002, 0.5000, 0.4998], [0.0001, 0.5000, 0.4999], [0.0001, 0.5000, 0.4999], [0.0000, 0.5000, 0.5000]]",
    "classifyTransientRecurrent": "[[A_s0], [B1, C]]",
    "classifyPeriodicity": {
        "B1": "1.0000",
        "C": "1.0000"
    },
    "determineMCType": "ergodic unichain",
    "hittingProbabilities": {
        "A_s0": "1.0000",
        "B1": "1.0000",
        "C": "1.0000"
    },
    "limitingMatrix": "[[0.0000, 0.5000, 0.5000], [0.0000, 0.5000, 0.5000], [0.0000, 0.5000, 0.5000]]",
    "limitingDistribution": "[0.0000, 0.5000, 0.5000]",
    "longRunReward": "1.0000",
    "transient_reward_0_step_0": "1.0000",
    "transient_reward_10_step_0": "1.0000",
    "transient_reward_10_step_1": "1.5000",
    "transient_reward_10_step_2": "1.2500",
    "transient_reward_10_step_3": "1.1250",
    "transient_reward_10_step_4": "1.0625",
    "transient_reward_10_step_5": "1.0312",
    "transient_reward_10_step_6": "1.0156",
    "transient_reward_10_step_7": "1.0078",
    "transient_reward_10_step_8": "1.0039",
    "transient_reward_10_step_9": "1.0020",
    "transient_reward_10_step_10": "1.0010",
    "markovTrace_0": "[A_s0]",
    "markovTrace_15": "[A_s0, A_s0, B1, B1, C, C, C, B1, C, B1, B1, C, B1, B1, C, B1]",
    "longRunExpectedAverageReward_cycle": "[[1.0000, 1.0000], 0.0000, 0.0000, 1.0000, 1.0000, Number of cycles]",
    "longRunExpectedAverageReward_steps": "[None, None, None, 0.0000, -1.0000, Maximum path length]",
    "longRunExpectedAverageReward_abs": "[[0.5844, 1.1299], 0.2728, 0.4667, 0.8571, 12.0000, Absolute Error]",
    "longRunExpectedAverageReward_rel": "[[0.6116, 1.0436], 0.2160, 0.3532, 0.8276, 12.0000, Relative Error]",
    "cezaroLimitDistribution_cycle": "[None, [[0.0000, 0.0000], [-0.9800, 0.9800], [-0.9800, 0.9800]], [0.0000, 0.9800, 0.9800], [None, None, None], 1.0000, Number of cycles]",
    "cezaroLimitDistribution_steps": "[None, [None, None, None], [None, None, None], [None, None, None], 0.0000, Maximum path length]",
    "cezaroLimitDistribution_abs": "[None, [[0.0000, 0.0000], [-0.2437, 0.2437], [-0.4584, 0.4584]], [0.0000, 0.2437, 0.4584], [None, None, None], 13.0000, Absolute Error]",
    "cezaroLimitDistribution_rel": "[None, [[0.0000, 0.0000], [-0.0428, 0.0428], [-0.0781, 0.0781]], [0.0000, 0.0428, 0.0781], [None, None, None], 473.0000, Maximum path length]",
    "estimationExpectedReward_step": "[2.0000, [2.0000, 2.0000], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationExpectedReward_abs": "[1.4000, [1.2247, 1.5753], 0.1753, 0.1431, 30.0000, Absolute Error]",
    "estimationExpectedReward_rel": "[1.4333, [1.2560, 1.6107], 0.1773, 0.1412, 30.0000, Relative Error]",
    "estimationDistribution": "[[0.0000, 1.0000, 0.0000], [[0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000]], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationHittingState": "[[Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000], [None, 0.0000, 0.0000], [1.0000, None, None], [None, [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingreward": "[[1.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000], [[1.0000, 1.0000], [1.0000, 1.0000], [1.0000, 1.0000]], [Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingStateSet": "[[Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000], [None, None, 0.0000], [1.0000, 1.0000, None], [None, None, [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingRewardSet": "[[0.0000, 1.0000, 1.0000], [1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000], [None, 0.0000, 0.0000], [[0.0000, 0.0000], [1.0000, 1.0000], [1.0000, 1.0000]], [Number of Paths, Number of Paths, Number of Paths]]"
}