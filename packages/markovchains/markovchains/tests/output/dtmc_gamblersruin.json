{
    "states": "[S1, S2, S3, S4]",
    "rewardVector": "[0, 100, 200, 300]",
    "executeSteps_0": "[[0, 1/2, 1/2, 0]]",
    "executeSteps_15": "[[0, 1/2, 1/2, 0], [1/4, 1/4, 1/4, 1/4], [3/8, 1/8, 1/8, 3/8], [7/16, 1/16, 1/16, 7/16], [15/32, 1/32, 1/32, 15/32], [31/64, 1/64, 1/64, 31/64], [63/128, 1/128, 1/128, 63/128], [127/256, 1/256, 1/256, 127/256], [255/512, 1/512, 1/512, 255/512], [511/1024, 1/1024, 1/1024, 511/1024], [1023/2048, 1/2048, 1/2048, 1023/2048], [2047/4096, 1/4096, 1/4096, 2047/4096], [4095/8192, 1/8192, 1/8192, 4095/8192], [8191/16384, 1/16384, 1/16384, 8191/16384], [16383/32768, 1/32768, 1/32768, 16383/32768], [32767/65536, 1/65536, 1/65536, 32767/65536]]",
    "classifyTransientRecurrent": "[[S2, S3], [S1, S4]]",
    "classifyPeriodicity": {
        "S4": "1.0000",
        "S1": "1.0000"
    },
    "determineMCType": "ergodic non-unichain",
    "hittingProbabilities": {
        "S1": "1",
        "S2": "2/3",
        "S3": "1/3",
        "S4": "0"
    },
    "limitingMatrix": "[[1, 2/3, 1/3, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 1/3, 2/3, 1]]",
    "limitingDistribution": "[1/2, 0, 0, 1/2]",
    "longRunReward": "150",
    "transient_reward_0_step_0": "150",
    "transient_reward_10_step_0": "150",
    "transient_reward_10_step_1": "150",
    "transient_reward_10_step_2": "150",
    "transient_reward_10_step_3": "150",
    "transient_reward_10_step_4": "150",
    "transient_reward_10_step_5": "150",
    "transient_reward_10_step_6": "150",
    "transient_reward_10_step_7": "150",
    "transient_reward_10_step_8": "150",
    "transient_reward_10_step_9": "150",
    "transient_reward_10_step_10": "150",
    "markovTrace_0": "[S3]",
    "markovTrace_15": "[S2, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1, S1]",
    "longRunExpectedAverageReward_cycle": "[None, None, None, None, None, Number of cycles]",
    "longRunExpectedAverageReward_steps": "[None, None, None, None, None, Maximum path length]",
    "longRunExpectedAverageReward_abs": "[[300.0000, 300.0000], 0.0000, 0.0000, 300.0000, 0.0000, Absolute Error]",
    "longRunExpectedAverageReward_rel": "[[300.0000, 300.0000], 0.0000, 0.0000, 300.0000, 0.0000, Relative Error]",
    "cezaroLimitDistribution_cycle": "[None, [None, None, None, None], [None, None, None, None], None, None, Number of cycles]",
    "cezaroLimitDistribution_steps": "[None, [None, None, None, None], [None, None, None, None], None, None, Maximum path length]",
    "cezaroLimitDistribution_abs": "[[[1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0000], [0.0000, None, None, None], [1.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000], Absolute Error]",
    "cezaroLimitDistribution_rel": "[[[1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0000], [0.0000, None, None, None], [1.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000], Maximum path length]",
    "estimationExpectedReward_step": "[None, None, None, None, None, Number of Paths]",
    "estimationExpectedReward_abs": "[[149.3438, 150.3438], 0.5000, 0.0033, 149.8438, 111.7833, Absolute Error]",
    "estimationExpectedReward_rel": "[[130.6377, 209.3623], 39.3623, 0.3013, 170.0000, 110.0000, Relative Error]",
    "estimationDistribution": "[None, [None, None, None, None], [None, None, None, None], None, None, Number of Paths]",
    "estimationHittingState": "[{'S1': '[None, None, None, None, None]', 'S2': '[None, None, None, None, None]', 'S3': '[None, None, None, None, None]', 'S4': '[None, None, None, None, None]'}, {'S1': 'Number of Paths', 'S2': 'Number of Paths', 'S3': 'Number of Paths', 'S4': 'Number of Paths'}]",
    "estimationHittingreward": "[{'S1': '[None, None, None, None, None]', 'S2': '[None, None, None, None, None]', 'S3': '[None, None, None, None, None]', 'S4': '[None, None, None, None, None]'}, {'S1': 'Number of Paths', 'S2': 'Number of Paths', 'S3': 'Number of Paths', 'S4': 'Number of Paths'}]",
    "estimationHittingStateSet": "[{'S1': '[None, None, None, None, None]', 'S2': '[None, None, None, None, None]', 'S3': '[None, None, None, None, None]', 'S4': '[None, None, None, None, None]'}, {'S1': 'Number of Paths', 'S2': 'Number of Paths', 'S3': 'Number of Paths', 'S4': 'Number of Paths'}]",
    "estimationHittingRewardSet": "[{'S1': '[None, None, None, None, None]', 'S2': '[None, None, None, None, None]', 'S3': '[None, None, None, None, None]', 'S4': '[None, None, None, None, None]'}, {'S1': 'Number of Paths', 'S2': 'Number of Paths', 'S3': 'Number of Paths', 'S4': 'Number of Paths'}]"
}