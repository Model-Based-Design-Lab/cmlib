{
    "states": "[S1, S2, S3, S4, S5, S6, S7, S8]",
    "rewardVector": "[0, 0, 0, 0, 0, 0, 0, 0]",
    "executeSteps_0": "[[1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8]]",
    "executeSteps_15": "[[1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8], [0, 7/48, 1/24, 3/20, 7/40, 3/10, 3/32, 3/32], [0, 7/72, 7/144, 11/60, 1/6, 151/960, 39/320, 9/40], [0, 7/108, 7/216, 127/720, 73/360, 1759/5760, 77/768, 151/1280], [0, 7/162, 7/324, 113/540, 409/2160, 2503/13824, 1457/11520, 1759/7680], [0, 7/243, 7/486, 251/1296, 353/1620, 31199/103680, 29999/276480, 2503/18432], [0, 14/729, 7/729, 1073/4860, 3877/19440, 974473/4976640, 214793/1658880, 31199/138240], [0, 28/2187, 14/2187, 11743/58320, 655/2916, 8786809/29859840, 2263231/19906560, 974473/6635520], [0, 56/6561, 28/6561, 9881/43740, 35677/174960, 14781625/71663616, 7788251/59719680, 8786809/39813120], [0, 112/19683, 56/19683, 107479/524880, 29867/131220, 30917311/107495424, 167367137/1433272320, 14781625/95551488], [0, 224/59049, 112/59049, 17965/78732, 324229/1574640, 5526703111/25798901760, 1120447631/8599633920, 30917311/143327232], [0, 448/177147, 224/177147, 974479/4723920, 270371/1180980, 43592165071/154793410560, 12249388897/103195607040, 5526703111/34398535680], [0, 896/531441, 448/531441, 812009/3542940, 586121/2834352, 409625992163/1857520926720, 40170165881/309586821120, 43592165071/206391214080], [0, 1792/1594323, 896/1594323, 8798983/42515280, 2439611/10628820, 770199499019/2786281390080, 178333596547/1486016741376, 409625992163/2476694568960], [0, 3584/4782969, 1792/4782969, 7322417/31886460, 26425621/127545840, 30174880192489/133741506723840, 5755801944281/44580502241280, 770199499019/3715041853440], [0, 7168/14348907, 3584/14348907, 15861107/76527504, 21981587/95659380, 218285568370921/802449040343040, 12941938371635/106993205379072, 30174880192489/178322008965120]]",
    "classifyTransientRecurrent": "[[S1, S2, S3], [S4, S5, S6, S7, S8]]",
    "classifyPeriodicity": {
        "S4": "2.0000",
        "S5": "2.0000",
        "S8": "1.0000",
        "S6": "1.0000",
        "S7": "1.0000"
    },
    "determineMCType": "non-ergodic non-unichain",
    "hittingProbabilities": {
        "S1": "3/10",
        "S2": "3/5",
        "S3": "3/5",
        "S4": "1",
        "S5": "1",
        "S6": "0",
        "S7": "0",
        "S8": "0"
    },
    "limitingMatrix": "[[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3/20, 3/10, 3/10, 1/2, 1/2, 0, 0, 0], [3/20, 3/10, 3/10, 1/2, 1/2, 0, 0, 0], [14/45, 8/45, 8/45, 0, 0, 4/9, 4/9, 4/9], [7/45, 4/45, 4/45, 0, 0, 2/9, 2/9, 2/9], [7/30, 2/15, 2/15, 0, 0, 1/3, 1/3, 1/3]]",
    "limitingDistribution": "[0, 0, 0, 7/32, 7/32, 1/4, 1/8, 3/16]",
    "longRunReward": "0",
    "transient_reward_0_step_0": "0",
    "transient_reward_10_step_0": "0",
    "transient_reward_10_step_1": "0",
    "transient_reward_10_step_2": "0",
    "transient_reward_10_step_3": "0",
    "transient_reward_10_step_4": "0",
    "transient_reward_10_step_5": "0",
    "transient_reward_10_step_6": "0",
    "transient_reward_10_step_7": "0",
    "transient_reward_10_step_8": "0",
    "transient_reward_10_step_9": "0",
    "transient_reward_10_step_10": "0",
    "markovTrace_0": "[S7]",
    "markovTrace_15": "[S4, S5, S4, S5, S4, S5, S4, S5, S4, S5, S4, S5, S4, S5, S4, S5]",
    "longRunExpectedAverageReward_cycle": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 1.0000, Number of cycles]",
    "longRunExpectedAverageReward_steps": "[None, None, None, 0.0000, 0.0000, Maximum path length]",
    "longRunExpectedAverageReward_abs": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 15.0000, Absolute Error]",
    "longRunExpectedAverageReward_rel": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 449.0000, Maximum path length]",
    "cezaroLimitDistribution_cycle": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.9800, 0.9800], [-0.1633, 0.1633], [-0.8167, 0.8167]], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9800, 0.1633, 0.8167], [None, None, None, None, None, None, None, None], 1.0000, Number of cycles]",
    "cezaroLimitDistribution_steps": "[None, [None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None], -1.0000, Maximum path length]",
    "cezaroLimitDistribution_abs": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.2530, 0.2530], [-0.2530, 0.2530], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.2530, 0.2530, 0.0000, 0.0000, 0.0000], [None, None, None, None, None, None, None, None], 15.0000, Absolute Error]",
    "cezaroLimitDistribution_rel": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.0438, 0.0438], [-0.0438, 0.0438], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0438, 0.0438, 0.0000, 0.0000, 0.0000], [None, None, None, None, None, None, None, None], 500.0000, Maximum path length]",
    "estimationExpectedReward_step": "[0.0000, [0.0000, 0.0000], 0.0000, None, 1.0000, Number of Paths]",
    "estimationExpectedReward_abs": "[0.0000, [0.0000, 0.0000], 0.0000, None, 30.0000, Absolute Error]",
    "estimationExpectedReward_rel": "[0.0000, [0.0000, 0.0000], 0.0000, None, 1000.0000, Number of Paths]",
    "estimationDistribution": "[[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [[0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationHittingState": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, None, 0.0000, 0.0000, None, None, None], [1.0000, 1.0000, 1.0000, None, None, 1.0000, 1.0000, 1.0000], [None, None, None, [0.0000, 0.0000], [0.0000, 0.0000], None, None, None], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingreward": "[[0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, 0.0000, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingStateSet": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, None, None, 0.0000, None, None, None], [1.0000, 1.0000, 1.0000, 1.0000, None, 1.0000, 1.0000, 1.0000], [None, None, None, None, [0.0000, 0.0000], None, None, None], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingRewardSet": "[[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, None, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]"
}