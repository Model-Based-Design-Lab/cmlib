{
    "states": "[S1, S2, S3, S4, S5, S6, S7, S8]",
    "rewardVector": "[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]",
    "executeSteps_0": "[[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]]",
    "executeSteps_15": "[[0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250], [0.0000, 0.1458, 0.0417, 0.1500, 0.1750, 0.3000, 0.0938, 0.0938], [0.0000, 0.0972, 0.0486, 0.1833, 0.1667, 0.1573, 0.1219, 0.2250], [0.0000, 0.0648, 0.0324, 0.1764, 0.2028, 0.3054, 0.1003, 0.1180], [0.0000, 0.0432, 0.0216, 0.2093, 0.1894, 0.1811, 0.1265, 0.2290], [0.0000, 0.0288, 0.0144, 0.1937, 0.2179, 0.3009, 0.1085, 0.1358], [0.0000, 0.0192, 0.0096, 0.2208, 0.1994, 0.1958, 0.1295, 0.2257], [0.0000, 0.0128, 0.0064, 0.2014, 0.2246, 0.2943, 0.1137, 0.1469], [0.0000, 0.0085, 0.0043, 0.2259, 0.2039, 0.2063, 0.1304, 0.2207], [0.0000, 0.0057, 0.0028, 0.2048, 0.2276, 0.2876, 0.1168, 0.1547], [0.0000, 0.0038, 0.0019, 0.2282, 0.2059, 0.2142, 0.1303, 0.2157], [0.0000, 0.0025, 0.0013, 0.2063, 0.2289, 0.2816, 0.1187, 0.1607], [0.0000, 0.0017, 0.0008, 0.2292, 0.2068, 0.2205, 0.1298, 0.2112], [0.0000, 0.0011, 0.0006, 0.2070, 0.2295, 0.2764, 0.1200, 0.1654], [0.0000, 0.0007, 0.0004, 0.2296, 0.2072, 0.2256, 0.1291, 0.2073], [0.0000, 0.0005, 0.0002, 0.2073, 0.2298, 0.2720, 0.1210, 0.1692]]",
    "classifyTransientRecurrent": "[[S1, S2, S3], [S4, S5, S6, S7, S8]]",
    "classifyPeriodicity": {
        "S6": "1.0000",
        "S8": "1.0000",
        "S7": "1.0000",
        "S4": "2.0000",
        "S5": "2.0000"
    },
    "determineMCType": "non-ergodic non-unichain",
    "hittingProbabilities": {
        "S1": "0.3000",
        "S2": "0.6000",
        "S3": "0.6000",
        "S4": "1.0000",
        "S5": "1.0000",
        "S6": "0.0000",
        "S7": "0.0000",
        "S8": "0.0000"
    },
    "limitingMatrix": "[[0.0000, 0.0000, 0.0000, 0.1500, 0.1500, 0.3111, 0.1556, 0.2333], [0.0000, 0.0000, 0.0000, 0.3000, 0.3000, 0.1778, 0.0889, 0.1333], [0.0000, 0.0000, 0.0000, 0.3000, 0.3000, 0.1778, 0.0889, 0.1333], [0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333]]",
    "limitingDistribution": "[0.0000, 0.0000, 0.0000, 0.2188, 0.2188, 0.2500, 0.1250, 0.1875]",
    "longRunReward": "0.0000",
    "transient_reward_0_step_0": "0.0000",
    "transient_reward_10_step_0": "0.0000",
    "transient_reward_10_step_1": "0.0000",
    "transient_reward_10_step_2": "0.0000",
    "transient_reward_10_step_3": "0.0000",
    "transient_reward_10_step_4": "0.0000",
    "transient_reward_10_step_5": "0.0000",
    "transient_reward_10_step_6": "0.0000",
    "transient_reward_10_step_7": "0.0000",
    "transient_reward_10_step_8": "0.0000",
    "transient_reward_10_step_9": "0.0000",
    "transient_reward_10_step_10": "0.0000",
    "markovTrace_0": "[S7]",
    "markovTrace_15": "[S7, S7, S7, S6, S8, S6, S8, S6, S8, S6, S8, S6, S8, S6, S8, S6]",
    "longRunExpectedAverageReward_cycle": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 1.0000, Number of cycles]",
    "longRunExpectedAverageReward_steps": "[[None, None], None, None, 0.0000, 0.0000, Maximum path length]",
    "longRunExpectedAverageReward_abs": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 9.0000, Absolute Error]",
    "longRunExpectedAverageReward_rel": "[[0.0000, 0.0000], 0.0000, None, 0.0000, 499.0000, Maximum path length]",
    "cezaroLimitDistribution_cycle": "[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.5000], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.5000, 0.5000], [0.0000, 0.0000], [0.5000, 0.5000]], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, None, None, 0.0000, None, 0.0000], 1.0000, Number of cycles]",
    "cezaroLimitDistribution_steps": "[None, [[None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None], [None, None]], [None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None], 0.0000, Maximum path length]",
    "cezaroLimitDistribution_abs": "[[0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.5000, 0.5000], [0.5000, 0.5000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, 0.0000, 0.0000, None, None, None], 15.0000, Absolute Error]",
    "cezaroLimitDistribution_rel": "[[0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.5000, 0.5000], [0.5000, 0.5000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, 0.0000, 0.0000, None, None, None], 15.0000, Relative Error]",
    "estimationExpectedReward_step": "[0.0000, [0.0000, 0.0000], 0.0000, None, 1.0000, Number of Paths]",
    "estimationExpectedReward_abs": "[0.0000, [0.0000, 0.0000], 0.0000, None, 30.0000, Absolute Error]",
    "estimationExpectedReward_rel": "[0.0000, [0.0000, 0.0000], 0.0000, None, 1000.0000, Number of Paths]",
    "estimationDistribution": "[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000]], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationHittingState": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, 0.0000, 0.0000, 0.0000, None, None, None], [1.0000, 1.0000, None, None, None, 1.0000, 1.0000, 1.0000], [[None, None], [None, None], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [None, None], [None, None], [None, None]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingreward": "[[0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, 0.0000, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingStateSet": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, None, None, 0.0000, None, None, None], [1.0000, 1.0000, 1.0000, 1.0000, None, 1.0000, 1.0000, 1.0000], [[None, None], [None, None], [None, None], [None, None], [0.0000, 0.0000], [None, None], [None, None], [None, None]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingRewardSet": "[[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, None, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]"
}