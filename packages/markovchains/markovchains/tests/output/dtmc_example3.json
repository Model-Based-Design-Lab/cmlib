{
    "states": "[S1, S2, S3, S4, S5, S6, S7, S8]",
    "rewardVector": "[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]",
    "executeSteps_0": "[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]",
    "executeSteps_15": "[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000], [0.0000, 0.3333, 0.1667, 0.0000, 0.0000, 0.0000, 0.1250, 0.3750], [0.0000, 0.2222, 0.1111, 0.0333, 0.0667, 0.5042, 0.0625, 0.0000], [0.0000, 0.1481, 0.0741, 0.0889, 0.0778, 0.0757, 0.1573, 0.3781], [0.0000, 0.0988, 0.0494, 0.0926, 0.1185, 0.4864, 0.0976, 0.0568], [0.0000, 0.0658, 0.0329, 0.1284, 0.1123, 0.1253, 0.1704, 0.3648], [0.0000, 0.0439, 0.0219, 0.1189, 0.1416, 0.4632, 0.1165, 0.0940], [0.0000, 0.0293, 0.0146, 0.1460, 0.1277, 0.1610, 0.1741, 0.3474], [0.0000, 0.0195, 0.0098, 0.1306, 0.1518, 0.4402, 0.1273, 0.1208], [0.0000, 0.0130, 0.0065, 0.1538, 0.1345, 0.1883, 0.1737, 0.3302], [0.0000, 0.0087, 0.0043, 0.1358, 0.1564, 0.4196, 0.1339, 0.1412], [0.0000, 0.0058, 0.0029, 0.1572, 0.1376, 0.2099, 0.1719, 0.3147], [0.0000, 0.0039, 0.0019, 0.1382, 0.1584, 0.4018, 0.1384, 0.1574], [0.0000, 0.0026, 0.0013, 0.1588, 0.1389, 0.2274, 0.1697, 0.3014], [0.0000, 0.0017, 0.0009, 0.1392, 0.1593, 0.3867, 0.1417, 0.1706]]",
    "classifyTransientRecurrent": "[[S1, S2, S3], [S4, S5, S6, S7, S8]]",
    "classifyPeriodicity": {
        "S7": "1.0000",
        "S5": "2.0000",
        "S4": "2.0000",
        "S6": "1.0000",
        "S8": "1.0000"
    },
    "determineMCType": "non-ergodic non-unichain",
    "hittingProbabilities": {
        "S1": "0.3000",
        "S2": "0.6000",
        "S3": "0.6000",
        "S4": "1.0000",
        "S5": "1.0000",
        "S6": "0.0000",
        "S7": "0.0000",
        "S8": "0.0000"
    },
    "limitingMatrix": "[[0.0000, 0.0000, 0.0000, 0.1500, 0.1500, 0.3111, 0.1556, 0.2333], [0.0000, 0.0000, 0.0000, 0.3000, 0.3000, 0.1778, 0.0889, 0.1333], [0.0000, 0.0000, 0.0000, 0.3000, 0.3000, 0.1778, 0.0889, 0.1333], [0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4444, 0.2222, 0.3333]]",
    "limitingDistribution": "[0.0000, 0.0000, 0.0000, 0.1500, 0.1500, 0.3111, 0.1556, 0.2333]",
    "longRunReward": "1.0000",
    "transient_reward_0_step_0": "1.0000",
    "transient_reward_10_step_0": "1.0000",
    "transient_reward_10_step_1": "1.0000",
    "transient_reward_10_step_2": "1.0000",
    "transient_reward_10_step_3": "1.0000",
    "transient_reward_10_step_4": "1.0000",
    "transient_reward_10_step_5": "1.0000",
    "transient_reward_10_step_6": "1.0000",
    "transient_reward_10_step_7": "1.0000",
    "transient_reward_10_step_8": "1.0000",
    "transient_reward_10_step_9": "1.0000",
    "transient_reward_10_step_10": "1.0000",
    "markovTrace_0": "[S1]",
    "markovTrace_15": "[S1, S2, S2, S2, S3, S5, S4, S5, S4, S5, S4, S5, S4, S5, S4, S5]",
    "longRunExpectedAverageReward_cycle": "[[1.0000, 1.0000], 0.0000, 0.0000, 1.0000, 1.0000, Number of cycles]",
    "longRunExpectedAverageReward_steps": "[None, None, None, 0.0000, 0.0000, Maximum path length]",
    "longRunExpectedAverageReward_abs": "[[1.0000, 1.0000], 0.0000, 0.0000, 1.0000, 13.0000, Absolute Error]",
    "longRunExpectedAverageReward_rel": "[[1.0000, 1.0000], 0.0000, 0.0000, 1.0000, 14.0000, Relative Error]",
    "cezaroLimitDistribution_cycle": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.9800, 0.9800], [0.0000, 0.0000], [-0.9800, 0.9800]], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9800, 0.0000, 0.9800], [None, None, None, None, None, None, None, None], 1.0000, Number of cycles]",
    "cezaroLimitDistribution_steps": "[None, [None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None], [None, None, None, None, None, None, None, None], -1.0000, Maximum path length]",
    "cezaroLimitDistribution_abs": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.2718, 0.2718], [-0.2718, 0.2718], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.2718, 0.2718, 0.0000, 0.0000, 0.0000], [None, None, None, None, None, None, None, None], 13.0000, Absolute Error]",
    "cezaroLimitDistribution_rel": "[None, [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [-0.0441, 0.0441], [-0.0441, 0.0441], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [0.0000, 0.0000, 0.0000, 0.0441, 0.0441, 0.0000, 0.0000, 0.0000], [None, None, None, None, None, None, None, None], 494.0000, Maximum path length]",
    "estimationExpectedReward_step": "[1.0000, [1.0000, 1.0000], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationExpectedReward_abs": "[1.0000, [1.0000, 1.0000], 0.0000, 0.0000, 30.0000, Absolute Error]",
    "estimationExpectedReward_rel": "[1.0000, [1.0000, 1.0000], 0.0000, 0.0000, 30.0000, Relative Error]",
    "estimationDistribution": "[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000]], 0.0000, 0.0000, 1.0000, Number of Paths]",
    "estimationHittingState": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, 1.0000, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, None, 0.0000, 0.0000, None, None, None], [1.0000, 1.0000, 1.0000, None, 0.0000, 1.0000, 1.0000, 1.0000], [None, None, None, [0.0000, 0.0000], [1.0000, 1.0000], None, None, None], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingreward": "[[0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, 0.0000, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingStateSet": "[[Cannot be decided, Cannot be decided, Cannot be decided, Cannot be decided, 1.0000, Cannot be decided, Cannot be decided, Cannot be decided], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [None, None, None, None, 0.0000, None, None, None], [1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 1.0000, 1.0000], [None, None, None, None, [1.0000, 1.0000], None, None, None], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]",
    "estimationHittingRewardSet": "[[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000], [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [None, None, None, None, 0.0000, None, None, None], [[0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000], [1.0000, 1.0000], [0.0000, 0.0000], [0.0000, 0.0000], [0.0000, 0.0000]], [Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths, Number of Paths]]"
}